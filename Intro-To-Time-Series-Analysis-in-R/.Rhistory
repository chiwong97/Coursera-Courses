install.packages("devtools")
library(devtools)
install.packages("installr")
library(installr)
updateR()
install.packages("devtools")
library(devtools)
install.packages("dplyr")
install.packages("ggplot2")
install.packages("shiny")
install_github("StatsWithR/statsr")
install.packages("devtools")
library(devtools)
install.packages("devtools")
sessionInfo()
install.packages("rlang")
install.packages("devtools")
library(devtools)
library(statsr)
library(dplyr)
library(ggplot2)
data(nycflights)
names(nycflights)
?nycflights
str(nycflights)
ggplot(data = nycflights, aes(x = dep_delay)) +
geom_histogram()
ggplot(data = nycflights, aes(x = dep_delay)) +
geom_histogram(binwidth = 15)
ggplot(data = nycflights, aes(x = dep_delay)) +
geom_histogram(binwidth = 150)
rdu_flights <- nycflights %>%
filter(dest == "RDU")
ggplot(data = rdu_flights, aes(x = dep_delay)) +
geom_histogram()
rdu_flights %>%
summarise(mean_dd = mean(dep_delay), sd_dd = sd(dep_delay), n = n())
sfo_feb_flights <- nycflights %>%
filter(dest == "SFO", month == 2)
sfo_feb_flights <- nycflights %>%
filter(dest="SFO", month==2)
sfo_feb_flights <- nycflights %>%
filter(dest=="SFO", month==2)
View(sfo_feb_flights)
View(sfo_feb_flights)
ggplot(data=sfo_feb_flights, aes(x=arr_delay)) +
geom_histogram(binwidth=30)
ggplot(data=sfo_feb_flights, aes(x=arr_delay)) +
geom_histogram()
rdu_flights %>%
group_by(origin) %>%
summarise(mean_dd = mean(dep_delay), sd_dd = sd(dep_delay), n = n())
View(nycflights)
View(sfo_feb_flights)
sfo_feb_flights %>%
group_by(carrier) %>%
summarise(median_ad = median(arr_delay), iqr_ad = IQR(arr_delay))
nycflights %>%
group_by(month) %>%
summarise(mean_dd = mean(dep_delay)) %>%
arrange(desc(mean_dd))
sfo_feb_flights %>%
group_by(carrier) %>%
summarise(median_ad = median(arr_delay), iqr_ad = IQR(arr_delay)) %>%
arrange(desc(iqr_ad))
nycflights %>%
group_by(month) %>%
summarise(median_dd = median(dep_delay)) %>%
arrange(desc(median_dd))
ggplot(nycflights, aes(x = factor(month), y = dep_delay)) +
geom_boxplot()
nycflights <- nycflights %>%
mutate(dep_type = ifelse(dep_delay < 5, "on time", "delayed"))
nycflights %>%
group_by(origin) %>%
summarise(ot_dep_rate = sum(dep_type == "on time") / n()) %>%
arrange(desc(ot_dep_rate))
ggplot(data = nycflights, aes(x = origin, fill = dep_type)) +
geom_bar()
View(nycflights)
nycflights <- nycflights %>%
mutate(avg_speed = distance/(air_time/60))
nycflights %>%
group_by(tailnum) %>%
arrange(desc(avg_speed))
nycflights <- nycflights %>%
mutate(avg_speed = distance/(air_time/60))
nycflights %>%
group_by(tailnum) %>%
arrange(desc(avg_speed)) %>%
select(tailnum, avg_speed)
nycflights <- nycflights %>%
mutate(avg_speed = distance/(air_time/60)) %>%
group_by(tailnum) %>%
arrange(desc(avg_speed)) %>%
select(tailnum, avg_speed)
ggplot(data=nycflights, aes(x = distance, y=avg_speed)) + geom_point()
View(nycflights)
data(nycflights)
View(nycflights)
nycflights <- nycflights %>%
mutate(avg_speed = distance/(air_time/60))
nycflights %>%
group_by(tailnum) %>%
arrange(desc(avg_speed)) %>%
select(tailnum, avg_speed)
ggplot(data=nycflights, aes(x = distance, y=avg_speed)) + geom_point()
nycflights <- nycflights %>%
mutate(dep_type = ifelse(dep_delay < 5, "on time", "delayed"))
View(nycflights)
nycflights <- nycflights %>%
mutate(arr_type = ifelse(arr_delay <= 0, "on time", "delayed"))
nycflights %>%
group_by(dep_type) %>%
summarise(ot_arr_rate = sum(arr_type == "on time")/n())
library(statsr)
library(dplyr)
library(ggplot2)
data(kobe_basket)
force(kobe_basket)
?kobe_basket
View(kobe_basket)
kobe_streak <- calc_streak(kobe_basket$shot)
ggplot(data = kobe_streak, aes(x = length)) +
geom_histogram(binwidth = 1)
coin_outcomes <- c("heads", "tails")
sample(coin_outcomes, size = 1, replace = TRUE)
sim_fair_coin <- sample(coin_outcomes, size = 100, replace = TRUE)
sim_fair_coin
table(sim_fair_coin)
sim_unfair_coin <- sample(coin_outcomes, size = 100, replace = TRUE,
prob = c(0.2, 0.8))
sim_unfair_coin <- sample(coin_outcomes, size = 100, replace = TRUE,
prob = c(0.2, 0.8))
table(sim_unfair_coin)
sim_unfair_coin <- sample(coin_outcomes, size = 100, replace = TRUE,
prob = c(0.2, 0.8))
sim_unfair_coin
table(sim_unfair_coin)
shot_outcomes <- c("H", "M")
sim_basket <- sample(shot_outcomes, size = 133, replace = TRUE, prob = c(0.45,0.55))
shot_outcomes <- c("H", "M")
sim_basket <- sample(shot_outcomes, size = 133, replace = TRUE, prob = c(0.45,0.55))
sim_basket
table(sim_basket)
sim_streak = calc_streak(sim_basket)
ggplot(data = sim_streak, aes(x=length)) + geom_histogram(binwidth=1)
pnorm(-1, mean=0, sd=1)
pnorm(-2, mean=0, sd=1)
pnorm(-1.6, mean = 0, sd=1)
pnorm(1800, mean = 1500, sd=300)
pnorm(24, mean = 21, sd = 5)
qnorm(0.1, mean = 21, sd = 5)
qnorm(34,mean=24,sd=4)
pnorm(34, mean=24, sd=4)
## Load the tidyverse package
library(tidyverse)
## Load the ggplot2 package into the R workspace
library(ggplot2)
## Load the msleep data
data(msleep)
## Check the first 6 rows of the data
head(msleep)
## Check the dimension of the data
dim(msleep)
shape(msleep)
## Check the column names
names(msleep)
?msleep
## Check the number of missing values for each column
sapply(msleep, function(x), sum(is.na(x)))
## Check the number of missing values for each column
sapply(msleep, function(x) sum(is.na(x)))
## Using the map function to check for
## number of missing values
msleep %>%
map(is.na) %>%
map(sum)
## Calculate the proportion of missingness
## for each variable
msleep %>%
map(is.na) %>%
map(sum) %>%
map(~ ./nrow(msleep)) %>%
bind_cols()
## Calculate the proportion of missingness
## for each variable
msleep %>%
map(is.na) %>%
map(sum) %>%
map(~ ./nrow(msleep))
## Calculate the proportion of missingness
## for each variable
msleep %>%
map(is.na) %>%
map(sum) %>%
map(~ ./nrow(msleep)) %>%
bind_cols()
## Select the vore, sleep_rem, sleep_cycle, and brainwt
msleep_data <- msleep %>%
select(vore, sleep_rem, sleep_cycle, brainwt)
## Print the new msleep data
msleep_data
## Check the dimension of the new data
dim(msleep_data)
## Drop rows with NA values in the vore column
msleep_data <- msleep_data %>%
drop_na(vore)
## Check the dimension of the new data
dim(msleep_data)
## Replace the NA values in the sleep_rem
## column with integer zero values (0L).
msleep_data <- msleep_data %>%
replace_na(list(sleep_rem = 0L))
## Print the new msleep data
msleep_data
## Replace the missing values in the sleep_cycle column
## using the median of the values
msleep_data %>%
mutate(sleep_cycle = replace_na(sleep_cycle, replace = median(sleep_cycle), na.rm = TRUE))
## Replace the missing values in the sleep_cycle column
## using the median of the values
msleep_data %>%
mutate(sleep_cycle = replace_na(sleep_cycle, replace = median(sleep_cycle, na.rm = TRUE)))
## Replace the missing values in the sleep_cycle column
## using the median of the values
msleep_data %>%
replace_na(list(sleep_rem = 0L)) %>%
mutate(sleep_cycle = replace_na(sleep_cycle, replace = median(sleep_cycle, na.rm = TRUE)))
## Replace the missing values in the sleep_cycle column
## using the median of the values
msleep_data <- msleep_data %>%
replace_na(list(sleep_rem = 0L)) %>%
mutate(sleep_cycle = replace_na(sleep_cycle, replace = median(sleep_cycle, na.rm = TRUE)))
## Print the new msleep data
msleep_data
## Fill the brainwt column upwards
msleep_data %>%
fill(brainwt, .direction = 'up')
## Select the vore, sleep_rem, sleep_cycle, and brainwt
msleep_data <- msleep %>%
select(vore, sleep_rem, sleep_cycle, brainwt)
## Replace the NA values in the sleep_rem
## column with integer zero values (0L).
## Fill the brainwt column upwards
msleep_data <- msleep_data %>%
replace_na(sleep_rem, replace = 0L) %>%
fill(brainwt, .direction = 'up')
## Replace the NA values in the sleep_rem
## column with integer zero values (0L).
## Fill the brainwt column upwards
msleep_data <- msleep_data %>%
replace_na(list(sleep_rem), replace = 0L) %>%
fill(brainwt, .direction = 'up')
## Replace the NA values in the sleep_rem
## column with integer zero values (0L).
## Fill the brainwt column upwards
msleep_data <- msleep_data %>%
replace_na(list(sleep_rem = 0L)) %>%
fill(brainwt, .direction = 'up')
msleep_data
## Select the vore, sleep_rem, sleep_cycle, and brainwt
msleep_data <- msleep %>%
select(vore, sleep_rem, sleep_cycle, brainwt)
## Fill the missing values in the brainwt column
## "downup" and "updown".
msleep_data %>%
fill(brainwt, .direction='downup')
## Print the cleaned data
msleep_data
msleep_data %>%
fill(brainwt, .direction='updown')
## Chain all the steps together and
## save the result as msleep_data
msleep_data <- msleep_data %>%
replace_na(list(sleep_rem = 0L)) %>%
fill(brainwt, .direction = "up") %>%
mutate(sleep_cycle =
replace_na(sleep_cycle,
median(sleep_cycle, na.rm = T)))
## Print the cleaned data
msleep_data
## Chain all the steps together and
## save the result as msleep_data
msleep_data <- msleep_data %>%
drop_na(vore) %>%
replace_na(list(sleep_rem = 0L)) %>%
fill(brainwt, .direction = "up") %>%
mutate(sleep_cycle =
replace_na(sleep_cycle,
median(sleep_cycle, na.rm = T)))
## Print the cleaned data
msleep_data
?fill
install.packages('IRkernel')
IRkernel::installspec(user=FALSE)
setwd("C:/Users/User/OneDrive - The University of Melbourne/Projects/Coursera-Courses/Intro-To-Time-Series-Analysis-in-R")
# Load Helper R Functions
source("R Functions/compare_models_function.R")
View(compare.models)
View(compare.models)
source("R Functions/sim_random_walk_function.R")
source("R Functions/sim_stationary_example_function.R")
library(gridExtra)
# Load Packages
library(IRdisplay)
library(magrittr)
library(tidyverse)
library(scales)
library(forecast)
install.packages("forecast")
library(tseries)
library(ggthemes)
install.packages("ggthemes")
theme_set(theme_economist())
# Set working directory
setwd("C:/Users/User/OneDrive - The University of Melbourne/Projects/Coursera-Courses/Intro-To-Time-Series-Analysis-in-R")
# Load Packages
library(IRdisplay)
library(magrittr)
library(tidyverse)
library(scales)
library(gridExtra)
library(forecast)
library(tseries)
library(ggthemes)
theme_set(theme_economist())
# Load Helper R Functions - these are functions defined in another script
source("R Functions/compare_models_function.R")
source("R Functions/sim_random_walk_function.R")
source("R Functions/sim_stationary_example_function.R")
display_png(file = "Images/times_series_dinosaur.png")
display_png(file = "Images/time_series_dinosaur.png")
# Run a function to compare linear regression to basic AR(1) time series models
# This function was predefined in a different script
compare.models(n=100)
# Dark blue line - forecast from the model
# Yellow - resulting confidence intervals
### LINEAR REGRESSION FORECAST
# We can see that the linear regression forecast doesn't account for
# compounding error - CI width should increase over time because we are
# making successive future predictions.
### TIME SERIES FORECAST
# In the time series forecast, the error bands actually widen as more and
# more predictions are made - this makes sense because we are forecasting
# using what we have forecasted, so there is more variance.
compare.models(n=10000)
# KEY CONCEPTS: Autocorrelation/Autocovariance
# simulate a random walk
dat <- sim.random.walk()
# plot the random walk
dat %>%
ggplot(dat$X, type = "correlation") +
ggtitle("Autocorrelation ACF Plot")
# plot the random walk
dat %>%
ggplot(aes(t,X)) +
geom_line() +
xlab("T") +
ylav("X") +
ggtitle("Time Series Plot")
# plot the random walk
dat %>%
ggplot(aes(t,X)) +
geom_line() +
xlab("T") +
ylab("X") +
ggtitle("Time Series Plot")
View(sim.random.walk)
# ACF plot
ggAcf(dat$X, type = "correlation") +
ggtitle("Autocorrelation ACF Plot")
# PACF plot
ggAcf(dat$X, type="partial") +
ggtitle("Partial Autocorrelation PACF Plot")
# KEY CONCEPTS: Stationarity
# Checking for stationarity
df <- sim.stationary.example(n=1000)
head(df)
dim(df)
# EXAMPLE:
# Plot non-stationary time series (x1 and x2)
g1 <- ggplot(df, aes(x=t, y=X1)) +
geom_line() +
xlab("t") +
ylab("X1") +
ggtitle("Non-Stationary X1")
g2 <- ggplot(df, aes(x=t, y=X2)) +
geom_line() +
xlab("t") +
ylab("X2") +
ggtitle("Non-Stationary X2")
g3 <- ggplot(df, aes(x=t, y=X3)) +
geom_line() +
xlab("t") +
ylab("X3") +
ggtitle("Stationary X3")
# View both plots simultaneously
grid.arrange(g1,g3)
# EXAMPLE:
# Plot ACF for stationary
g4 <- ggAcf(df$X1, type="correlation") +
xlab("t") +
ylab("X1") +
ggtitle("Non-Stationary X1")
# Plot ACF for non-stationary
g5 <- ggAcf(df$X3, type="correlation") +
xlab("t") +
ylab("X3") +
ggtitle("Stationary X3")
grid.arrange(g4,g5)
# EXAMPLE:
# Non-stationary has large, non-significant p-value
adf.test(df$X1)
# Stationary has small, significant p-value
adf.test(df$X3)
grid.arrange(g6,g7)
### TRANSFORMING FOR STATIONARITY
# METHOD 1: DIFFERENCING
diff <- df$X1 - lag(df$X1, 1)
g6 <- ggAcf(df$X1, type="correlation")
g7 <- ggAcf(diff, type="correlation")
grid.arrange(g6,g7)
# METHOD 2: DETRENDING
# we detrend with the linear regression model
detrended <- resid(lm(X1~t, data=df))
g8 <- ggAcf(detrended, type="correlation")
grid.arrange(g6,g8)
# METHOD 2: DETRENDING
# we detrend with the linear regression model
detrended <- resid(lm(X2~t, data=df))
g8 <- ggAcf(df$X2, type="correlation")
g9 <- ggAcf(detrended, type="correlation")
grid.arrange(g8,g9)
ur <- read.csv("Data/Mass Monthly Unemployment Rate.csv")
head(ur)
dim(ur)
class(ur$DATE)
ur$DATE <- as.Date(ur$DATE)
# Transform data types
class(ur$DATE)
ggplot(ur, aes(x=DATE, y=MAURN)) +
geom_line()
# Method 2 - ACF plot
ggAcf(ur$MAURN, type="correlation")
# Method 3 - ADF test
adf.test(ur$MAURN)
# Step 2: Transform for Stationarity and Identify Model Parameters
# AR model
ar.model <- auto.arima(ur$MAURN, max.d=0, max.q=0, allowdrift=TRUE)
ar.model
# MA model
ma.model <- auto.arima(ur$MAURN, max.d=0, max.p=0, allowdrift=TRUE)
ma.model
# ARMA model
arma.model <- auto.arima(ur$MAURN, max.d=0, allowdrift=TRUE)
arma.model
# ARIMA model
arima.model <- auto.arima(ur$MAURN, allowdrift=TRUE)
arima.model
# Step 3: Check the residuals of the model fit
ar.residual <- resid(ar.model)
ma.residual <- resid(ma.model)
arma.residual <- resid(arma.model)
arima.residual <- resid(arima.model)
# Plot a PACF plot
ggAcf(ar.residual, type="partial")
ggAcf(ma.residual, type="partial")
ggAcf(arma.residual, type="partial")
ggAcf(arima.residual, type="partial")
# Run the Ljung Box test
Box.test(ar.residual, type="Ljung-Box", lag=1)
Box.test(ma.residual, type="Ljung-Box", lag=1)
Box.test(arma.residual, type="Ljung-Box", lag=1)
Box.test(arima.residual, type="Ljung-Box", lag=1)
# Step 4: Forecast
ar.forecast <- forecast(ar.model, h=24, level=80)
ma.forecast <- forecast(ma.model, h=24, level=80)
arma.forecast <- forecast(arma.model, h=24, level=80)
arima.forecast <- forecast(arima.model, h=24, level=80)
# Plot forecasts
g10 <- autoplot(ar.forecast)
g11 <- autoplot(ma.forecast)
g12 <- autoplot(arma.forecast)
g13 <- autoplot(arima.forecast)
grid.arrange(g10,g11,g12,g13)
# ASIDE: Model 5
# STL (Seasonal Trend Losses) Decomposition Models
# Transform to times series object and specify the frequency
ur.ts <- ts(ur$MAURN, frequency=12)
# Fit STL model
stl.model <- stl(ur.ts, s.window="periodic")
# Plot model
autoplot(stl.model)
# Forecast
stl.forecast <- forecast(stl.model, h=24, level=80)
autoplot(stl.forecast)
